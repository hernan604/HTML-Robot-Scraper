use HTML::Robot::Scraper;

my $robot = HTML::Robot::Scraper->new( {
  instructions => {

      #What to do with web pages, read  data
      read  => 'HTML::Robot::Scraper::Reader::BBC',

      #How to save web page data, write data
      write => 'HTML::Robot::Scraper::Writer::Data'

  },
  local_cache => {
      #save pages localy, good when developing/offline testing
      enabled => 1,
      directory => '/home/catalyst/HTML-Robot-Scraper/cache/',
  },
  before_normalize_url => {
      #OPTIONAL. Use to skip urls
      is_active => 1,
      code => sub {
          my ( $url ) = @_;
          return undef if $url =~ m/^#/gi;
          $url =~ s/([^#]+)#(.+)/$1/g;
          return $url;
      }
  },
  images => {
      enabled => 1,
      content_type => [
        qw|
          image/gif
          image/jpeg
          image/pjpeg
          image/png
        |
      ],
      directory => '/home/images',
  },
  engines => {
      queue => 'HTML::Robot::Scraper::Engine::Queue::Array', # Array|Redis
      user_agent => {
        class => 'HTML::Robot::Scraper::Engine::UserAgent::HTTP::Tiny',
        constructor_args => { #Optional, its HTTP::Tiny constructor args..
            agent => 'Mozilla',
            proxy => '127.0.0.1:228',
        },
      },
  },
  parsers => {
      process => {
          'text/html' => {                        #processa content type com modulos
              with_class => 'HTML::Robot::Scraper::Parser::HTML::TreeBuilder::XPath',
              use_method => 'parse_xpath', #method within class^^ that will receive content and parse
          },
          'text/xml' => {
              with_class => 'HTML::Robot::Scraper::Parser::XML::XPath',
              use_method => 'parse_xml', #method inside that class that will receive content and parse
          },
      }
  },
} );
